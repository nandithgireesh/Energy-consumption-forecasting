{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# âš¡ Day 2 â€” Data Preprocessing & Feature Engineering\n",
                "## Energy Consumption Forecasting | Claysys AI Hackathon 2026\n",
                "\n",
                "**Date:** February 20, 2026  \n",
                "**Objective:** Clean the dataset, handle missing values, resample to hourly frequency, and engineer rich features for ML/DL models.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from src.data_loader import load_raw_data, resample_data, split_train_test\n",
                "from src.preprocessing import (\n",
                "    clean_data, remove_outliers, add_time_features,\n",
                "    add_lag_features, add_rolling_features, add_energy_derived_features, normalize\n",
                ")\n",
                "\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "plt.rcParams.update({'figure.dpi': 120, 'font.size': 10})\n",
                "print('âœ… Setup complete for Day 2')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Raw Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_PATH = '../data/raw/household_power_consumption.txt'\n",
                "df_raw = load_raw_data(DATA_PATH, verbose=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Handle Missing Values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Linear interpolation is ideal for time series â€” preserves temporal continuity\n",
                "df_clean = clean_data(df_raw, strategy='interpolate')\n",
                "\n",
                "print(f'\\nRemaining NaN after cleaning: {df_clean.isna().sum().sum()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Resample to Hourly Frequency"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Resample minute-level â†’ hourly averages (reduces noise, more practical for forecasting)\n",
                "df_hourly = resample_data(df_clean, freq='h')\n",
                "df_hourly = df_hourly.dropna()  # Drop any remaining NaN after resampling\n",
                "\n",
                "print(f'\\nHourly dataset shape: {df_hourly.shape}')\n",
                "df_hourly.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Outlier Detection & Removal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
                "\n",
                "axes[0].boxplot(df_hourly['Global_active_power'].dropna(), vert=False)\n",
                "axes[0].set_title('Before Outlier Removal', fontweight='bold')\n",
                "axes[0].set_xlabel('Global Active Power (kW)')\n",
                "\n",
                "df_hourly = remove_outliers(df_hourly, 'Global_active_power', z_thresh=4.0)\n",
                "\n",
                "axes[1].boxplot(df_hourly['Global_active_power'].dropna(), vert=False)\n",
                "axes[1].set_title('After Outlier Removal', fontweight='bold')\n",
                "axes[1].set_xlabel('Global Active Power (kW)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../reports/figures/outlier_removal.png', bbox_inches='tight')\n",
                "plt.show()\n",
                "print(f'Dataset shape after outlier removal: {df_hourly.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Add domain-knowledge derived features\n",
                "df_feat = add_energy_derived_features(df_hourly)\n",
                "\n",
                "# Step 2: Add calendar + cyclical time features\n",
                "df_feat = add_time_features(df_feat)\n",
                "\n",
                "# Step 3: Add lag features (hourly lags: 1h, 2h, 3h, 6h, 12h, 24h, 48h, 168h=1week)\n",
                "df_feat = add_lag_features(df_feat, target_col='Global_active_power',\n",
                "                            lags=[1, 2, 3, 6, 12, 24, 48, 168])\n",
                "\n",
                "# Step 4: Add rolling statistics\n",
                "df_feat = add_rolling_features(df_feat, target_col='Global_active_power',\n",
                "                                windows=[3, 6, 12, 24, 48, 168])\n",
                "\n",
                "# Drop rows with NaN caused by lag/rolling features\n",
                "df_feat = df_feat.dropna()\n",
                "\n",
                "print(f'\\nFinal feature set shape: {df_feat.shape}')\n",
                "print(f'Total features: {df_feat.shape[1]}')\n",
                "print(f'\\nAll features:\\n{list(df_feat.columns)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Feature Importance Preview (Correlation with Target)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numeric_cols = df_feat.select_dtypes(include=[np.number]).columns\n",
                "corr_with_target = df_feat[numeric_cols].corr()['Global_active_power'].drop('Global_active_power')\n",
                "corr_sorted = corr_with_target.abs().sort_values(ascending=False).head(20)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "colors = ['#F44336' if v > 0 else '#2196F3' for v in corr_with_target[corr_sorted.index]]\n",
                "ax.barh(corr_sorted.index[::-1], corr_sorted.values[::-1], color=colors[::-1], alpha=0.85)\n",
                "ax.set_title('Top 20 Features by Correlation with Global Active Power', fontweight='bold')\n",
                "ax.set_xlabel('|Pearson Correlation|')\n",
                "ax.axvline(0.5, color='gray', linestyle='--', linewidth=1, label='0.5 threshold')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.savefig('../reports/figures/feature_correlation_target.png', bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Train / Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hold out last 3 months for final testing\n",
                "train_df, test_df = split_train_test(df_feat, test_months=3)\n",
                "\n",
                "print(f'\\nTrain shape : {train_df.shape}')\n",
                "print(f'Test shape  : {test_df.shape}')\n",
                "\n",
                "# Visualize the split\n",
                "fig, ax = plt.subplots(figsize=(14, 4))\n",
                "ax.plot(train_df.index, train_df['Global_active_power'], label='Train', color='steelblue', linewidth=0.7)\n",
                "ax.plot(test_df.index, test_df['Global_active_power'], label='Test (hold-out)', color='tomato', linewidth=0.7)\n",
                "ax.axvline(test_df.index.min(), color='black', linestyle='--', linewidth=1.5, label='Split point')\n",
                "ax.set_title('Train / Test Split', fontweight='bold')\n",
                "ax.set_ylabel('Global Active Power (kW)')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.savefig('../reports/figures/train_test_split.png', bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Normalize Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import joblib\n",
                "from pathlib import Path\n",
                "\n",
                "# Select numeric columns for scaling (exclude encoded categoricals)\n",
                "scale_cols = [c for c in df_feat.select_dtypes(include=[np.number]).columns\n",
                "              if c not in ['is_weekend', 'hour', 'dayofweek', 'month', 'quarter', 'year', 'dayofyear', 'weekofyear']]\n",
                "\n",
                "train_scaled, test_scaled, scaler = normalize(train_df, test_df, columns=scale_cols, method='minmax')\n",
                "\n",
                "# Save the scaler for use in later notebooks\n",
                "Path('../models').mkdir(exist_ok=True)\n",
                "joblib.dump(scaler, '../models/minmax_scaler.pkl')\n",
                "print('ðŸ’¾ Scaler saved to models/minmax_scaler.pkl')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Save Processed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Path('../data/processed').mkdir(exist_ok=True)\n",
                "\n",
                "# Save full feature set (unscaled â€” models can scale internally)\n",
                "df_feat.to_csv('../data/processed/features_hourly.csv')\n",
                "train_df.to_csv('../data/processed/train.csv')\n",
                "test_df.to_csv('../data/processed/test.csv')\n",
                "\n",
                "print('âœ… Processed datasets saved:')\n",
                "print('   â†’ data/processed/features_hourly.csv')\n",
                "print('   â†’ data/processed/train.csv')\n",
                "print('   â†’ data/processed/test.csv')\n",
                "print(f'\\nðŸŽ‰ Day 2 Complete! {df_feat.shape[1]} features engineered.')\n",
                "print('   Ready for Day 3: Baseline Statistical Models (ARIMA, Holt-Winters)')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}