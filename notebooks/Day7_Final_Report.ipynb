{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ‚ö° Day 7 ‚Äî Final Report, Model Comparison & Submission\n",
                "## Energy Consumption Forecasting | Claysys AI Hackathon 2026\n",
                "\n",
                "**Date:** February 25, 2026  \n",
                "**Objective:** Compile the complete evaluation report, create the final dashboard, and prepare submission materials.\n",
                "\n",
                "---\n",
                "\n",
                "## üóìÔ∏è 7-Day Journey Summary\n",
                "\n",
                "| Day | Work Done |\n",
                "|-----|----------|\n",
                "| Day 1 | Dataset EDA ‚Äî 2M+ records, identified seasonal patterns |\n",
                "| Day 2 | Preprocessing ‚Äî interpolation, resampling, 60+ engineered features |\n",
                "| Day 3 | Baseline models ‚Äî Naive, Holt-Winters, ARIMA |\n",
                "| Day 4 | ML models ‚Äî Random Forest, XGBoost, LightGBM |\n",
                "| Day 5 | Deep learning ‚Äî LSTM, GRU (PyTorch) |\n",
                "| Day 6 | Prophet + Ensemble stacking |\n",
                "| Day 7 | Final evaluation, dashboard, submission |\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.gridspec as gridspec\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from pathlib import Path\n",
                "from src.evaluation import compare_models, plot_model_comparison\n",
                "\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "plt.rcParams.update({'figure.dpi': 130, 'font.size': 10})\n",
                "print('‚úÖ Day 7 Final Report Setup complete')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load All Model Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_results = pd.read_csv('../reports/all_model_results.csv', index_col=0)\n",
                "all_results = all_results.sort_values('RMSE')\n",
                "\n",
                "print('üìä FINAL MODEL LEADERBOARD')\n",
                "print('=' * 55)\n",
                "print(all_results[['MAE', 'RMSE', 'MAPE', 'R¬≤']].to_string())\n",
                "print('=' * 55)\n",
                "print(f'\\nü•á BEST MODEL : {all_results.index[0]}')\n",
                "print(f'   MAE        : {all_results[\"MAE\"].iloc[0]:.4f} kW')\n",
                "print(f'   RMSE       : {all_results[\"RMSE\"].iloc[0]:.4f} kW')\n",
                "print(f'   MAPE       : {all_results[\"MAPE\"].iloc[0]:.2f} %')\n",
                "print(f'   R¬≤         : {all_results[\"R¬≤\"].iloc[0]:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Final Dashboard ‚Äî All Models Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = plt.figure(figsize=(18, 10))\n",
                "gs = gridspec.GridSpec(2, 2, figure=fig, hspace=0.4, wspace=0.35)\n",
                "\n",
                "# --- RMSE Bar Chart ---\n",
                "ax1 = fig.add_subplot(gs[0, 0])\n",
                "colors = plt.cm.RdYlGn_r(np.linspace(0.05, 0.95, len(all_results)))\n",
                "bars = ax1.barh(all_results.index[::-1], all_results['RMSE'][::-1], color=colors[::-1])\n",
                "ax1.bar_label(bars, fmt='%.4f', padding=3, fontsize=8)\n",
                "ax1.set_title('RMSE Comparison (lower is better)', fontweight='bold')\n",
                "ax1.set_xlabel('RMSE (kW)')\n",
                "\n",
                "# --- MAE Bar Chart ---\n",
                "ax2 = fig.add_subplot(gs[0, 1])\n",
                "bars2 = ax2.barh(all_results.index[::-1], all_results['MAE'][::-1], color=colors[::-1])\n",
                "ax2.bar_label(bars2, fmt='%.4f', padding=3, fontsize=8)\n",
                "ax2.set_title('MAE Comparison (lower is better)', fontweight='bold')\n",
                "ax2.set_xlabel('MAE (kW)')\n",
                "\n",
                "# --- MAPE Bar Chart ---\n",
                "ax3 = fig.add_subplot(gs[1, 0])\n",
                "bars3 = ax3.barh(all_results.index[::-1], all_results['MAPE'][::-1], color=colors[::-1])\n",
                "ax3.bar_label(bars3, fmt='%.2f%%', padding=3, fontsize=8)\n",
                "ax3.set_title('MAPE Comparison (lower is better)', fontweight='bold')\n",
                "ax3.set_xlabel('MAPE (%)')\n",
                "\n",
                "# --- R¬≤ Bar Chart ---\n",
                "ax4 = fig.add_subplot(gs[1, 1])\n",
                "colors_r2 = plt.cm.RdYlGn(np.linspace(0.05, 0.95, len(all_results)))\n",
                "bars4 = ax4.barh(all_results.sort_values('R¬≤').index,\n",
                "                  all_results.sort_values('R¬≤')['R¬≤'],\n",
                "                  color=colors_r2)\n",
                "ax4.bar_label(bars4, fmt='%.4f', padding=3, fontsize=8)\n",
                "ax4.set_title('R¬≤ Score Comparison (higher is better)', fontweight='bold')\n",
                "ax4.set_xlabel('R¬≤')\n",
                "ax4.set_xlim(0, 1.1)\n",
                "\n",
                "fig.suptitle('‚ö° Energy Consumption Forecasting ‚Äî Final Model Dashboard',\n",
                "             fontsize=14, fontweight='bold', y=1.01)\n",
                "plt.savefig('../reports/figures/final_dashboard.png', bbox_inches='tight', dpi=150)\n",
                "plt.show()\n",
                "print('üíæ Final dashboard saved!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Best Model ‚Äî Detailed Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load test data\n",
                "test_df = pd.read_csv('../data/processed/test.csv', index_col='Datetime', parse_dates=True)\n",
                "\n",
                "# Re-load results from best model (example: XGBoost or Ensemble)\n",
                "# NOTE: In practice, load the saved predictions from Day 4/6\n",
                "# For the report, we will show the leaderboard analysis\n",
                "\n",
                "best_model_name  = all_results.index[0]\n",
                "best_model_rmse  = all_results['RMSE'].iloc[0]\n",
                "best_model_mape  = all_results['MAPE'].iloc[0]\n",
                "best_model_r2    = all_results['R¬≤'].iloc[0]\n",
                "\n",
                "print(f'Best Model   : {best_model_name}')\n",
                "print(f'RMSE         : {best_model_rmse:.4f} kW')\n",
                "print(f'MAPE         : {best_model_mape:.2f} %')\n",
                "print(f'R¬≤           : {best_model_r2:.4f}')\n",
                "print(f'Improvement  : {(all_results[\"RMSE\"].iloc[-1] - best_model_rmse)/all_results[\"RMSE\"].iloc[-1]*100:.1f}% over naive baseline')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Final Report ‚Äî Key Findings & Conclusions\n",
                "\n",
                "### üìä Project Summary\n",
                "This project successfully built an end-to-end energy consumption forecasting pipeline for household electricity usage using ~4 years of 1-minute interval data.\n",
                "\n",
                "### üî¨ Methodology\n",
                "1. **EDA**: Discovered strong daily (morning/evening peaks), weekly (weekday vs weekend), and annual (winter vs summer) seasonality patterns.\n",
                "2. **Preprocessing**: Linear interpolation handled 1.25% missing values. Resampled to hourly frequency. Engineered 60+ features including lags, rolling statistics, cyclical encodings, and domain-derived power features.\n",
                "3. **Statistical Models**: Established baselines. Holt-Winters captured daily seasonality. ARIMA modeled short-term trends.\n",
                "4. **ML Models**: Tree-based models (Random Forest, XGBoost, LightGBM) significantly outperformed statistical baselines by leveraging rich lag features.\n",
                "5. **Deep Learning**: LSTM and GRU captured sequential dependencies across 24-hour look-back windows.\n",
                "6. **Prophet**: Effectively decomposed trend + multiple seasonalities without extensive feature engineering.\n",
                "7. **Ensemble**: Weighted combination of best models achieved the lowest error overall.\n",
                "\n",
                "### üí° Key Insights\n",
                "- **Hour of day** and **24-hour lag** are the most predictive features\n",
                "- **Winter** months see 30-40% higher consumption than summer\n",
                "- **Evening peak** (6-10 PM) accounts for the highest hourly usage\n",
                "- Ensemble stacking consistently outperforms any single model\n",
                "\n",
                "### üöÄ Future Work\n",
                "- Incorporate external weather data (temperature, humidity)\n",
                "- Deploy as a real-time REST API with streaming predictions\n",
                "- Expand to multi-step (24h, 48h, 7-day ahead) forecasting\n",
                "- Explore Temporal Fusion Transformer (TFT) for attention-based forecasting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('=' * 60)\n",
                "print('üèÜ HACKATHON SUBMISSION SUMMARY')\n",
                "print('=' * 60)\n",
                "print(f'Project : Energy Consumption Forecasting')\n",
                "print(f'Event   : Claysys AI Hackathon 2026')\n",
                "print(f'Dataset : Household Power Consumption (UCI)')\n",
                "print(f'Records : 2,075,259 minute-level readings (2006‚Äì2010)')\n",
                "print(f'Models  : 8 (Naive, Holt-Winters, ARIMA, RF, XGB, LGBM, LSTM, GRU, Prophet, Ensemble)')\n",
                "print()\n",
                "print('üìã SUBMISSION CHECKLIST')\n",
                "print('  ‚úÖ GitHub repository with regular commits')\n",
                "print('  ‚úÖ Jupyter notebooks for all 7 days')\n",
                "print('  ‚úÖ README.md with full documentation')\n",
                "print('  ‚úÖ Source code modules (src/)')\n",
                "print('  ‚úÖ All models compared and evaluated')\n",
                "print('  ‚¨ú  Google Colab notebook link (upload and add link to README)')\n",
                "print('  ‚¨ú  YouTube demo video (record and upload as unlisted)')\n",
                "print()\n",
                "print('üîó Submit at: https://forms.office.com/r/yjUQQ8fFa9')\n",
                "print('=' * 60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}