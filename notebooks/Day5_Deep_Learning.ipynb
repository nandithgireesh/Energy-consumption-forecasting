{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# âš¡ Day 5 â€” Deep Learning: LSTM & GRU with PyTorch\n",
                "## Energy Consumption Forecasting | Claysys AI Hackathon 2026\n",
                "\n",
                "**Date:** February 23, 2026  \n",
                "**Objective:** Build and train LSTM and GRU sequence models to capture temporal dependencies in energy consumption.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from src.preprocessing import create_sequences, normalize\n",
                "from src.models.lstm_model import DeepLearningForecaster\n",
                "from src.evaluation import compute_metrics, plot_predictions, compare_models\n",
                "\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "plt.rcParams.update({'figure.dpi': 120})\n",
                "\n",
                "print(f'âœ… PyTorch version: {torch.__version__}')\n",
                "print(f'   CUDA available: {torch.cuda.is_available()}')\n",
                "print(f'   Device: {\"GPU\" if torch.cuda.is_available() else \"CPU\"}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load & Prepare Sequence Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df = pd.read_csv('../data/processed/train.csv', index_col='Datetime', parse_dates=True)\n",
                "test_df  = pd.read_csv('../data/processed/test.csv',  index_col='Datetime', parse_dates=True)\n",
                "\n",
                "# For LSTM: use target + key features as multivariate input\n",
                "FEATURES = [\n",
                "    'Global_active_power',    # Target (always first column)\n",
                "    'Global_reactive_power',\n",
                "    'Voltage',\n",
                "    'Global_intensity',\n",
                "    'Sub_metering_1',\n",
                "    'Sub_metering_2',\n",
                "    'Sub_metering_3',\n",
                "    'hour_sin', 'hour_cos',\n",
                "    'month_sin', 'month_cos',\n",
                "    'dow_sin', 'dow_cos',\n",
                "    'is_weekend',\n",
                "]\n",
                "\n",
                "FEATURES = [f for f in FEATURES if f in train_df.columns]\n",
                "\n",
                "train_data = train_df[FEATURES].dropna()\n",
                "test_data  = test_df[FEATURES].dropna()\n",
                "\n",
                "print(f'Train data: {train_data.shape}')\n",
                "print(f'Test data : {test_data.shape}')\n",
                "print(f'Features  : {FEATURES}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import MinMaxScaler\n",
                "\n",
                "# Scale all features to [0,1]\n",
                "scaler = MinMaxScaler()\n",
                "train_scaled = scaler.fit_transform(train_data.values)\n",
                "test_scaled  = scaler.transform(test_data.values)\n",
                "\n",
                "# Create sliding-window sequences\n",
                "SEQ_LENGTH = 24    # Look back 24 hours\n",
                "HORIZON    = 1     # Predict 1 step ahead\n",
                "\n",
                "X_train, y_train = create_sequences(train_scaled, seq_length=SEQ_LENGTH, horizon=HORIZON)\n",
                "X_test,  y_test  = create_sequences(test_scaled,  seq_length=SEQ_LENGTH, horizon=HORIZON)\n",
                "\n",
                "print(f'X_train shape: {X_train.shape}   (samples, timesteps, features)')\n",
                "print(f'X_test  shape: {X_test.shape}')\n",
                "print(f'y_train shape: {y_train.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Train LSTM Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split off validation set from end of training\n",
                "val_size = int(len(X_train) * 0.1)\n",
                "X_tr, X_val = X_train[:-val_size], X_train[-val_size:]\n",
                "y_tr, y_val = y_train[:-val_size], y_train[-val_size:]\n",
                "\n",
                "lstm_model = DeepLearningForecaster(\n",
                "    model_type='LSTM',\n",
                "    input_size=len(FEATURES),\n",
                "    hidden_size=128,\n",
                "    num_layers=2,\n",
                "    dropout=0.2,\n",
                "    seq_length=SEQ_LENGTH,\n",
                "    batch_size=64,\n",
                "    learning_rate=1e-3\n",
                ")\n",
                "\n",
                "lstm_model.fit(X_tr, y_tr, X_val=X_val, y_val=y_val, epochs=50, patience=10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lstm_model.plot_training_history(save=True)\n",
                "\n",
                "lstm_preds_scaled = lstm_model.predict(X_test)\n",
                "\n",
                "# Inverse-transform predictions (only the target column, index 0)\n",
                "def inverse_scale_target(preds_scaled, scaler, n_features):\n",
                "    dummy = np.zeros((len(preds_scaled), n_features))\n",
                "    dummy[:, 0] = preds_scaled\n",
                "    return scaler.inverse_transform(dummy)[:, 0]\n",
                "\n",
                "lstm_preds = inverse_scale_target(lstm_preds_scaled, scaler, len(FEATURES))\n",
                "y_test_actual = inverse_scale_target(y_test, scaler, len(FEATURES))\n",
                "\n",
                "metrics_lstm = compute_metrics(y_test_actual, lstm_preds, model_name='LSTM')\n",
                "plot_predictions(y_test_actual[:168], lstm_preds[:168],\n",
                "                 model_name='LSTM (First Week of Test)',\n",
                "                 filename='lstm_predictions.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train GRU Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gru_model = DeepLearningForecaster(\n",
                "    model_type='GRU',\n",
                "    input_size=len(FEATURES),\n",
                "    hidden_size=128,\n",
                "    num_layers=2,\n",
                "    dropout=0.2,\n",
                "    seq_length=SEQ_LENGTH,\n",
                "    batch_size=64,\n",
                "    learning_rate=1e-3\n",
                ")\n",
                "\n",
                "gru_model.fit(X_tr, y_tr, X_val=X_val, y_val=y_val, epochs=50, patience=10)\n",
                "gru_model.plot_training_history(save=True)\n",
                "\n",
                "gru_preds_scaled = gru_model.predict(X_test)\n",
                "gru_preds = inverse_scale_target(gru_preds_scaled, scaler, len(FEATURES))\n",
                "\n",
                "metrics_gru = compute_metrics(y_test_actual, gru_preds, model_name='GRU')\n",
                "plot_predictions(y_test_actual[:168], gru_preds[:168],\n",
                "                 model_name='GRU (First Week of Test)',\n",
                "                 filename='gru_predictions.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. LSTM vs GRU Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_day5 = [metrics_lstm, metrics_gru]\n",
                "comparison_df = compare_models(results_day5)\n",
                "comparison_df.to_csv('../reports/dl_results.csv')\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(14, 5))\n",
                "n = 168\n",
                "ax.plot(y_test_actual[:n], label='Actual', color='black', linewidth=1.5, zorder=5)\n",
                "ax.plot(lstm_preds[:n], label='LSTM', color='#9C27B0', linewidth=1.2, linestyle='--')\n",
                "ax.plot(gru_preds[:n],  label='GRU',  color='#00BCD4', linewidth=1.2, linestyle='--')\n",
                "ax.set_title('LSTM vs GRU â€” 1 Week Forecast', fontweight='bold')\n",
                "ax.set_ylabel('Global Active Power (kW)')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.savefig('../reports/figures/lstm_gru_comparison.png', bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('\\nðŸŽ‰ Day 5 Complete! Deep learning models trained.')\n",
                "print('   Ready for Day 6: Prophet + Ensemble Stacking')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}