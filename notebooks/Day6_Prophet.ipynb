{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ‚ö° Day 6 ‚Äî Facebook Prophet + Ensemble Stacking\n",
                "## Energy Consumption Forecasting | Claysys AI Hackathon 2026\n",
                "\n",
                "**Date:** February 24, 2026  \n",
                "**Objective:** Apply Meta's Prophet model and build an ensemble that combines the best models from previous days.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import joblib\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from src.models.prophet_model import ProphetForecaster\n",
                "from src.evaluation import compute_metrics, plot_predictions, compare_models, plot_model_comparison\n",
                "\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "plt.rcParams.update({'figure.dpi': 120})\n",
                "print('‚úÖ Day 6 Setup complete')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df = pd.read_csv('../data/processed/train.csv', index_col='Datetime', parse_dates=True)\n",
                "test_df  = pd.read_csv('../data/processed/test.csv',  index_col='Datetime', parse_dates=True)\n",
                "\n",
                "train_series = train_df['Global_active_power']\n",
                "test_series  = test_df['Global_active_power']\n",
                "\n",
                "print(f'Train: {len(train_series):,} hourly records')\n",
                "print(f'Test : {len(test_series):,} hourly records')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Facebook Prophet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prophet needs ds + y format, handled inside ProphetForecaster\n",
                "prophet_model = ProphetForecaster(\n",
                "    seasonality_mode='additive',\n",
                "    yearly_seasonality=True,\n",
                "    weekly_seasonality=True,\n",
                "    daily_seasonality=True,\n",
                "    changepoint_prior_scale=0.05,\n",
                ")\n",
                "\n",
                "# Fit on training series\n",
                "prophet_model.fit(train_series)\n",
                "\n",
                "# Predict for the test horizon\n",
                "prophet_preds = prophet_model.get_predictions_array(len(test_series), freq='h')\n",
                "metrics_prophet = compute_metrics(test_series.values, prophet_preds, model_name='Prophet')\n",
                "\n",
                "prophet_model.plot_forecast(save=True)\n",
                "prophet_model.plot_components(save=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_predictions(test_series.values[:168], prophet_preds[:168],\n",
                "                 index=test_df.index[:168],\n",
                "                 model_name='Prophet (First Week of Test)',\n",
                "                 filename='prophet_predictions.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Ensemble: Weighted Average of Best Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load ML predictions already generated in Day 4\n",
                "# (Re-generate them here for the ensemble)\n",
                "from src.models.ml_models import RandomForestForecaster, XGBoostForecaster, LightGBMForecaster\n",
                "\n",
                "drop_cols = ['season']\n",
                "train_ml = train_df.drop(columns=[c for c in drop_cols if c in train_df.columns])\n",
                "test_ml  = test_df.drop(columns=[c for c in drop_cols if c in test_df.columns])\n",
                "\n",
                "TARGET = 'Global_active_power'\n",
                "feature_cols = [c for c in train_ml.select_dtypes(include=[np.number]).columns if c != TARGET]\n",
                "\n",
                "X_train, y_train = train_ml[feature_cols], train_ml[TARGET]\n",
                "X_test,  y_test  = test_ml[feature_cols],  test_ml[TARGET]\n",
                "\n",
                "# Load or re-fit models\n",
                "xgb_model = XGBoostForecaster(n_estimators=500, learning_rate=0.05)\n",
                "xgb_model.fit(X_train.iloc[:int(len(X_train)*0.9)], y_train.iloc[:int(len(y_train)*0.9)])\n",
                "xgb_preds = xgb_model.predict(X_test)\n",
                "\n",
                "lgbm_model = LightGBMForecaster(n_estimators=500, learning_rate=0.05)\n",
                "lgbm_model.fit(X_train.iloc[:int(len(X_train)*0.9)], y_train.iloc[:int(len(y_train)*0.9)])\n",
                "lgbm_preds = lgbm_model.predict(X_test)\n",
                "\n",
                "print('‚úÖ ML models re-fitted for ensemble.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Weighted Ensemble: XGBoost 40% + LightGBM 40% + Prophet 20%\n",
                "ensemble_preds = 0.40 * xgb_preds + 0.40 * lgbm_preds + 0.20 * prophet_preds\n",
                "metrics_ensemble = compute_metrics(y_test.values, ensemble_preds, model_name='Ensemble (XGB+LGBM+Prophet)')\n",
                "\n",
                "plot_predictions(y_test.values[:168], ensemble_preds[:168],\n",
                "                 index=test_df.index[:168],\n",
                "                 model_name='Ensemble (First Week of Test)',\n",
                "                 filename='ensemble_predictions.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. All-Model Comparison (Day 6 Summary)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load previous day metrics\n",
                "baseline_results = pd.read_csv('../reports/baseline_results.csv', index_col=0)\n",
                "ml_results       = pd.read_csv('../reports/ml_results.csv', index_col=0)\n",
                "\n",
                "# Add today's results\n",
                "new_results = pd.DataFrame([metrics_prophet, metrics_ensemble]).set_index('Model')\n",
                "\n",
                "# Combine all\n",
                "all_results = pd.concat([baseline_results, ml_results, new_results])\n",
                "all_results = all_results.sort_values('RMSE')\n",
                "\n",
                "print('\\nüèÜ FULL MODEL LEADERBOARD:')\n",
                "print(all_results.to_string())\n",
                "\n",
                "all_results.to_csv('../reports/all_model_results.csv')\n",
                "\n",
                "plot_model_comparison(all_results, metric='RMSE')\n",
                "plot_model_comparison(all_results, metric='MAPE')\n",
                "\n",
                "print('\\nüéâ Day 6 Complete! Prophet + Ensemble done.')\n",
                "print(f'   ü•á Best Model: {all_results.index[0]} (RMSE={all_results[\"RMSE\"].iloc[0]:.4f})')\n",
                "print('   Ready for Day 7: Final Report & Submission!')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}